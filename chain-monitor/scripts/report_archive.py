#!/usr/bin/env python3
"""
é“¾ä¸Šé¡¹ç›®ç›‘æ§ - æŠ¥å‘Šç”Ÿæˆä¸å½’æ¡£ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. ç”Ÿæˆ48å°æ—¶å†…æ´»è·ƒé¡¹ç›®æŠ¥å‘Š
2. è¿‡æœŸé¡¹ç›®æŒ‰æ—¥æœŸå½’æ¡£åˆ° archive/YYYY-MM-DD.md
3. ç»´æŠ¤ç´¢å¼•æ–‡ä»¶ archive/INDEX.mdï¼ˆæ—¥æœŸã€é¡¹ç›®åã€åˆçº¦åœ°å€ï¼‰
"""

import json
import os
import time
from datetime import datetime, timedelta

ARCHIVE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "archive")
INDEX_FILE = os.path.join(ARCHIVE_DIR, "INDEX.md")
REPORT_FILE = os.path.join(ARCHIVE_DIR, "REPORT_48H.md")
ENRICHED_FILE = "/tmp/backtest_48h_enriched.json"
STATE_FILE = "/tmp/gmgn_monitor_state.json"

os.makedirs(ARCHIVE_DIR, exist_ok=True)

NOW = int(time.time())
CUTOFF_48H = NOW - 48 * 3600


def load_projects():
    """åŠ è½½æ‰€æœ‰å·²çŸ¥é¡¹ç›®ï¼ˆenriched + state ä¸­çš„å†å²è®°å½•ï¼‰"""
    projects = []
    # ä» enriched æ–‡ä»¶åŠ è½½
    if os.path.exists(ENRICHED_FILE):
        with open(ENRICHED_FILE) as f:
            projects = json.load(f)
    return projects


def load_archive_db():
    """åŠ è½½å·²å½’æ¡£é¡¹ç›®æ•°æ®åº“"""
    db_file = os.path.join(ARCHIVE_DIR, "archive_db.json")
    if os.path.exists(db_file):
        with open(db_file) as f:
            return json.load(f)
    return {}


def save_archive_db(db):
    db_file = os.path.join(ARCHIVE_DIR, "archive_db.json")
    with open(db_file, 'w') as f:
        json.dump(db, f, ensure_ascii=False, indent=2)


def format_mc(val):
    if val >= 1_000_000_000:
        return f"${val/1_000_000_000:.2f}B"
    elif val >= 1_000_000:
        return f"${val/1_000_000:.2f}M"
    elif val >= 1_000:
        return f"${val/1_000:.0f}K"
    return f"${val:.0f}"


def format_project_block(p, idx, symbol_counts=None):
    """æ ¼å¼åŒ–å•ä¸ªé¡¹ç›®ä¸º markdown å—"""
    lines = []
    ai_tag = "ğŸ¤–" if p.get('is_ai_mining') else "ğŸ“Š"
    sym = p['symbol']
    cnt = symbol_counts.get(sym, 1) if symbol_counts else 1
    if cnt > 1:
        sym = f"{sym} ({p['address'][:6]}) [åŒåÃ—{cnt}]"
    lines.append(f"### {ai_tag} #{idx} {sym}")
    lines.append(f"")
    lines.append(f"- åˆçº¦: `{p['address']}`")
    lines.append(f"- MC: {format_mc(p.get('market_cap', 0))} | æµåŠ¨æ€§: {format_mc(p.get('liquidity', 0))}")
    if p.get('holders'):
        lines.append(f"- æŒæœ‰äºº: {p['holders']:,}")
    lines.append(f"- å¹´é¾„: {p.get('age_hours', 0)}h | æ¥æº: {p.get('source', '?')}")
    if p.get('website'):
        lines.append(f"- ğŸŒ {p['website']}")
    if p.get('twitter'):
        lines.append(f"- ğŸ¦ @{p['twitter']}")
    if p.get('telegram'):
        lines.append(f"- ğŸ’¬ {p['telegram']}")
    lines.append(f"- ğŸ”— [GMGN](https://gmgn.ai/base/token/{p['address']})")
    if p.get('ai_keywords'):
        lines.append(f"- å…³é”®è¯: {', '.join(p['ai_keywords'])}")
    lines.append("")
    return "\n".join(lines)


def generate_48h_report(projects):
    """ç”Ÿæˆ48å°æ—¶å†…æ´»è·ƒé¡¹ç›®æŠ¥å‘Š"""
    active = [p for p in projects if p.get('age_hours', 999) <= 48]
    active.sort(key=lambda x: (not x.get('is_ai_mining', False), -x.get('open_timestamp', 0)))

    now_str = datetime.now().strftime('%Y-%m-%d %H:%M')

    # åŒåæ£€æµ‹
    from collections import Counter
    _sc = Counter(p['symbol'] for p in active)

    # ç–‘ä¼¼å‡å¸‚å€¼åˆ¤æ–­
    def _is_fake_mc(p):
        liq = p.get('liquidity', 0)
        mc = p.get('market_cap', 0)
        return liq > 0 and mc / liq > 1000

    ai_projects = [p for p in active if p.get('is_ai_mining') and not _is_fake_mc(p)]
    normal = [p for p in active if not p.get('is_ai_mining') and not _is_fake_mc(p)]
    fake_mc = [p for p in active if _is_fake_mc(p)]

    lines = []
    lines.append(f"# é“¾ä¸Šé¡¹ç›®ç›‘æ§ - 48å°æ—¶æŠ¥å‘Š")
    lines.append(f"")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {now_str}")
    lines.append(f"é¡¹ç›®æ€»æ•°: {len(active)} | AIæŒ–çŸ¿: {len(ai_projects)} | å…¶ä»–: {len(normal)} | ç–‘ä¼¼å‡å¸‚å€¼: {len(fake_mc)}")
    lines.append(f"")

    # AI æŒ–çŸ¿é¡¹ç›®
    if ai_projects:
        lines.append(f"## ğŸ¤– AI æŒ–çŸ¿é¡¹ç›® ({len(ai_projects)})")
        lines.append("")
        for i, p in enumerate(ai_projects, 1):
            lines.append(format_project_block(p, i, _sc))
            lines.append("---")
            lines.append("")

    # å…¶ä»–é¡¹ç›®
    if normal:
        lines.append(f"## ğŸ“Š å…¶ä»–é¡¹ç›® ({len(normal)})")
        lines.append("")
        for i, p in enumerate(normal, len(ai_projects) + 1):
            lines.append(format_project_block(p, i, _sc))
            lines.append("---")
            lines.append("")

    # ç–‘ä¼¼å‡å¸‚å€¼
    if fake_mc:
        lines.append(f"## âš ï¸ ç–‘ä¼¼å‡å¸‚å€¼ ({len(fake_mc)})")
        lines.append("")
        for i, p in enumerate(fake_mc, len(ai_projects) + len(normal) + 1):
            lines.append(format_project_block(p, i, _sc))
            lines.append("---")
            lines.append("")

    report = "\n".join(lines)
    with open(REPORT_FILE, 'w') as f:
        f.write(report)
    print(f"âœ… 48å°æ—¶æŠ¥å‘Šå·²ç”Ÿæˆ: {REPORT_FILE} ({len(active)} ä¸ªé¡¹ç›®)")
    return active


def archive_expired(projects):
    """å°†è¿‡æœŸé¡¹ç›®ï¼ˆ>48hï¼‰æŒ‰æ—¥æœŸå½’æ¡£"""
    expired = [p for p in projects if p.get('age_hours', 0) > 48]
    if not expired:
        print("ğŸ“­ æ²¡æœ‰è¿‡æœŸé¡¹ç›®éœ€è¦å½’æ¡£")
        return

    # åŠ è½½å·²æœ‰å½’æ¡£æ•°æ®åº“
    db = load_archive_db()

    # æŒ‰å¼€ç›˜æ—¥æœŸåˆ†ç»„
    by_date = {}
    for p in expired:
        ts = p.get('open_timestamp', 0)
        if ts:
            date_str = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
        else:
            date_str = "unknown"
        by_date.setdefault(date_str, []).append(p)

    new_archived = 0
    for date_str, date_projects in sorted(by_date.items()):
        # æ£€æŸ¥å“ªäº›æ˜¯æ–°çš„
        existing_addrs = set()
        if date_str in db:
            existing_addrs = {p['address'] for p in db[date_str]}

        new_projects = [p for p in date_projects if p['address'] not in existing_addrs]
        if not new_projects:
            continue

        # åˆå¹¶åˆ°æ•°æ®åº“
        if date_str not in db:
            db[date_str] = []
        db[date_str].extend(new_projects)
        new_archived += len(new_projects)

        # ç”Ÿæˆ/æ›´æ–°æ—¥æœŸå½’æ¡£æ–‡ä»¶
        archive_file = os.path.join(ARCHIVE_DIR, f"{date_str}.md")
        all_day_projects = db[date_str]
        all_day_projects.sort(key=lambda x: (not x.get('is_ai_mining', False), -x.get('open_timestamp', 0)))

        ai_count = sum(1 for p in all_day_projects if p.get('is_ai_mining'))
        day_sc = Counter(p['symbol'] for p in all_day_projects)
        lines = []
        lines.append(f"# é“¾ä¸Šé¡¹ç›®å½’æ¡£ - {date_str}")
        lines.append(f"")
        lines.append(f"é¡¹ç›®æ€»æ•°: {len(all_day_projects)} | AIæŒ–çŸ¿: {ai_count}")
        lines.append(f"")

        for i, p in enumerate(all_day_projects, 1):
            lines.append(format_project_block(p, i, day_sc))
            lines.append("---")
            lines.append("")

        with open(archive_file, 'w') as f:
            f.write("\n".join(lines))
        print(f"ğŸ“ å½’æ¡£ {date_str}: {len(all_day_projects)} ä¸ªé¡¹ç›® (æ–°å¢ {len(new_projects)})")

    save_archive_db(db)
    update_index(db)
    print(f"âœ… å½’æ¡£å®Œæˆï¼Œæ–°å¢ {new_archived} ä¸ªé¡¹ç›®")


def update_index(db):
    """æ›´æ–°ç´¢å¼•æ–‡ä»¶"""
    from collections import Counter
    # å…¨å±€åŒåæ£€æµ‹
    _all_symbols = Counter()
    for projects in db.values():
        for p in projects:
            _all_symbols[p['symbol']] += 1

    lines = []
    lines.append("# é“¾ä¸Šé¡¹ç›®å½’æ¡£ç´¢å¼•")
    lines.append("")
    lines.append(f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append("")

    total = 0
    total_ai = 0

    lines.append("| æ—¥æœŸ | é¡¹ç›®æ•° | AIæŒ–çŸ¿ | é¡¹ç›®åˆ—è¡¨ |")
    lines.append("|------|--------|---------|----------|")

    for date_str in sorted(db.keys(), reverse=True):
        projects = db[date_str]
        ai_count = sum(1 for p in projects if p.get('is_ai_mining'))
        total += len(projects)
        total_ai += ai_count

        # é¡¹ç›®ç®€è¦åˆ—è¡¨ï¼ˆåŒååŠ åˆçº¦å‰ç¼€ï¼‰
        names = []
        for p in projects:
            tag = "ğŸ¤–" if p.get('is_ai_mining') else ""
            sym = p['symbol']
            if _all_symbols.get(sym, 1) > 1:
                sym = f"{sym}({p['address'][:6]})"
            names.append(f"{tag}{sym}")
        names_str = ", ".join(names[:8])
        if len(names) > 8:
            names_str += f" +{len(names)-8}"

        lines.append(f"| [{date_str}]({date_str}.md) | {len(projects)} | {ai_count} | {names_str} |")

    lines.append("")
    lines.append(f"**æ€»è®¡: {total} ä¸ªé¡¹ç›® | AIæŒ–çŸ¿: {total_ai}**")
    lines.append("")

    # å®Œæ•´åˆçº¦åœ°å€ç´¢å¼•
    lines.append("## åˆçº¦åœ°å€ç´¢å¼•")
    lines.append("")
    lines.append("| æ—¥æœŸ | é¡¹ç›® | åˆçº¦åœ°å€ | AI |")
    lines.append("|------|------|----------|-----|")

    for date_str in sorted(db.keys(), reverse=True):
        for p in db[date_str]:
            ai = "ğŸ¤–" if p.get('is_ai_mining') else ""
            sym = p['symbol']
            if _all_symbols.get(sym, 1) > 1:
                sym = f"{sym} ({p['address'][:6]})"
            lines.append(f"| {date_str} | {sym} | `{p['address']}` | {ai} |")

    lines.append("")

    with open(INDEX_FILE, 'w') as f:
        f.write("\n".join(lines))
    print(f"ğŸ“‹ ç´¢å¼•å·²æ›´æ–°: {INDEX_FILE}")


def main():
    print("=" * 50)
    print("é“¾ä¸Šé¡¹ç›®ç›‘æ§ - æŠ¥å‘Šç”Ÿæˆä¸å½’æ¡£")
    print("=" * 50)

    projects = load_projects()
    if not projects:
        print("âŒ æ²¡æœ‰é¡¹ç›®æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå›æµ‹æˆ–ç­‰å¾…ç›‘æ§æ”¶é›†æ•°æ®")
        return

    print(f"åŠ è½½ {len(projects)} ä¸ªé¡¹ç›®")

    # 1. ç”Ÿæˆ48å°æ—¶æŠ¥å‘Š
    active = generate_48h_report(projects)

    # 2. å½’æ¡£è¿‡æœŸé¡¹ç›®
    archive_expired(projects)

    print("\nâœ… å…¨éƒ¨å®Œæˆ")


if __name__ == '__main__':
    main()
